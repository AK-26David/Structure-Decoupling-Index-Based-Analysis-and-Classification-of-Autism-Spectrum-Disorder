{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76cb083f",
   "metadata": {},
   "source": [
    "# SDI calculation for HCP (Normal) Patient Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44ef2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "import csv\n",
    "\n",
    "def compute_structural_laplacian(A):\n",
    "    D = np.diag(np.sum(A, axis=1))\n",
    "    with np.errstate(divide='ignore'):\n",
    "        D_inv_sqrt = np.diag(1.0 / np.sqrt(np.sum(A, axis=1)))\n",
    "    D_inv_sqrt[np.isinf(D_inv_sqrt)] = 0\n",
    "    L = np.eye(A.shape[0]) - D_inv_sqrt @ A @ D_inv_sqrt\n",
    "    return L\n",
    "\n",
    "def graph_spectral_phase_randomize(X, eigvecs, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    X_hat = X @ eigvecs  # project into graph spectral domain\n",
    "    T, N = X_hat.shape\n",
    "    X_surr = np.zeros_like(X_hat)\n",
    "\n",
    "    for i in range(N):\n",
    "        fft_coeff = np.fft.fft(X_hat[:, i])\n",
    "        mag = np.abs(fft_coeff)\n",
    "        phase = np.angle(fft_coeff)\n",
    "        num_phases = len(fft_coeff)\n",
    "\n",
    "        random_phases = np.random.uniform(0, 2*np.pi, num_phases // 2 - 1)\n",
    "        new_phase = np.copy(phase)\n",
    "        new_phase[1:num_phases//2] = random_phases\n",
    "        new_phase[-(num_phases//2)+1:] = -random_phases[::-1]\n",
    "\n",
    "        new_fft = mag * np.exp(1j * new_phase)\n",
    "        X_surr[:, i] = np.fft.ifft(new_fft).real\n",
    "\n",
    "    return X_surr @ eigvecs.T  # back-project into time domain\n",
    "\n",
    "def compute_SDI_informed(A, X, num_surrogates=100, K_ratio=0.3, seed=None):\n",
    "    # Preprocess functional data: demean and normalize each node timeseries\n",
    "    X = X - X.mean(axis=0)\n",
    "    X = X / (X.std(axis=0) + 1e-10)\n",
    "\n",
    "    T, N = X.shape\n",
    "    L = compute_structural_laplacian(A)\n",
    "    eigvals, eigvecs = eigh(L)\n",
    "\n",
    "    K = int(np.floor(N * K_ratio))\n",
    "    if K == 0 or K == N:\n",
    "        raise ValueError(f\"Invalid K: {K} for N={N} and K_ratio={K_ratio}\")\n",
    "\n",
    "    Vlow, Vhigh = eigvecs[:, :K], eigvecs[:, K:]\n",
    "\n",
    "    N_c_surr, N_d_surr = np.empty((N, num_surrogates)), np.empty((N, num_surrogates))\n",
    "\n",
    "    for s in range(num_surrogates):\n",
    "        X_surr = graph_spectral_phase_randomize(X, eigvecs, seed=seed+s)\n",
    "        X_hat = X_surr @ eigvecs\n",
    "\n",
    "        X_c = X_hat[:, :K] @ Vlow.T\n",
    "        X_d = X_hat[:, K:] @ Vhigh.T\n",
    "\n",
    "        for r in range(N):\n",
    "            N_c_surr[r, s] = np.linalg.norm(X_c[:, r])\n",
    "            N_d_surr[r, s] = np.linalg.norm(X_d[:, r])\n",
    "\n",
    "    SDI = N_d_surr / (N_c_surr + 1e-10)\n",
    "    mean_SDI = np.mean(SDI, axis=1)\n",
    "    print(f\"Informed SDI stats: mean={mean_SDI.mean():.4f}, std={mean_SDI.std():.4f}\")\n",
    "    return mean_SDI\n",
    "\n",
    "\n",
    "def main(functional_dir, structural_dir, output_csv_path, num_surrogates=100, K_ratio=0.3, seed=42):\n",
    "    func_files = {os.path.splitext(f)[0]: os.path.join(functional_dir, f)\n",
    "                  for f in os.listdir(functional_dir) if f.endswith('.ts')}\n",
    "    struct_files = {os.path.splitext(f)[0].replace('_5000', ''): os.path.join(structural_dir, f)\n",
    "                    for f in os.listdir(structural_dir) if f.endswith('.sc')}\n",
    "\n",
    "    common_patients = set(func_files.keys()) & set(struct_files.keys())\n",
    "    print(f\"Found {len(common_patients)} patients with matching data.\")\n",
    "\n",
    "    results = []\n",
    "    max_nodes = 0\n",
    "\n",
    "    for pid in sorted(common_patients):\n",
    "        func_path = func_files[pid]\n",
    "        struct_path = struct_files[pid]\n",
    "\n",
    "        try:\n",
    "            X = np.loadtxt(func_path)\n",
    "            A = np.loadtxt(struct_path)\n",
    "\n",
    "            if X.size == 0 or A.size == 0:\n",
    "                print(f\"Skipping {pid}: empty data\")\n",
    "                continue\n",
    "\n",
    "            if len(A.shape) != 2 or A.shape[0] != A.shape[1]:\n",
    "                print(f\"Skipping {pid}: Structural matrix not square {A.shape}\")\n",
    "                continue\n",
    "\n",
    "            if len(X.shape) != 2:\n",
    "                print(f\"Skipping {pid}: Functional data not 2D {X.shape}\")\n",
    "                continue\n",
    "\n",
    "            T, N_f = X.shape\n",
    "            N_s = A.shape[0]\n",
    "\n",
    "            if N_f != N_s:\n",
    "                if N_s > N_f:\n",
    "                    A = A[:N_f, :N_f]\n",
    "                    N_s = N_f\n",
    "                    print(f\"Truncated structural matrix for {pid} from {A.shape[0]} to {N_f} nodes\")\n",
    "                else:\n",
    "                    print(f\"Skipping {pid}: functional nodes > structural nodes (cannot truncate)\")\n",
    "                    continue\n",
    "\n",
    "            N = min(N_f, N_s)\n",
    "            if N == 0:\n",
    "                print(f\"Skipping {pid}: zero dimension after truncation\")\n",
    "                continue\n",
    "\n",
    "            X = X[:, :N]\n",
    "            A = A[:N, :N]\n",
    "\n",
    "            sdi = compute_SDI_informed(A, X, num_surrogates=num_surrogates, K_ratio=K_ratio, seed=seed)\n",
    "            sdi = np.log2(sdi + 1e-10)  # log transform, avoid log(0)\n",
    "\n",
    "            results.append((pid, sdi))\n",
    "            max_nodes = max(max_nodes, len(sdi))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pid}: {e}\")\n",
    "\n",
    "    with open(output_csv_path, 'w', newline='') as f_out:\n",
    "        writer = csv.writer(f_out)\n",
    "        header = ['PatientID'] + [f'SDI_Node_{i+1}' for i in range(max_nodes)]\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for pid, sdi in results:\n",
    "            row = [pid] + list(sdi) + [np.nan]*(max_nodes - len(sdi))\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"Saved all SDI results to {output_csv_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    functional_dir = \"/Users/arnavkarnik/Documents/Brain-Structure-Function-Coupling-and-Graph-Laplacians-in-Neuroimaging-for-Disease-Characterization/REST2_RL\"\n",
    "    structural_dir = \"/Users/arnavkarnik/Documents/Brain-Structure-Function-Coupling-and-Graph-Laplacians-in-Neuroimaging-for-Disease-Characterization/SC_yeo_100\"\n",
    "    output_csv_path = \"/Users/arnavkarnik/Documents/Brain-Structure-Function-Coupling-and-Graph-Laplacians-in-Neuroimaging-for-Disease-Characterization/SDI_results/all_patients_SDI_informed.csv\"\n",
    "    main(functional_dir, structural_dir, output_csv_path, num_surrogates=100, K_ratio=0.3, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b53744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "def plot_matrix(mat, title, cmap='viridis'):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(mat, cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def normalize_matrix(mat):\n",
    "    min_val = np.min(mat)\n",
    "    max_val = np.max(mat)\n",
    "    if max_val - min_val == 0:\n",
    "        return np.zeros_like(mat)\n",
    "    return (mat - min_val) / (max_val - min_val)\n",
    "\n",
    "def compute_structural_laplacian(A):\n",
    "    D = np.diag(np.sum(A, axis=1))\n",
    "    with np.errstate(divide='ignore'):\n",
    "        D_inv_sqrt = np.diag(1.0 / np.sqrt(np.sum(A, axis=1)))\n",
    "    D_inv_sqrt[np.isinf(D_inv_sqrt)] = 0\n",
    "    L = np.eye(A.shape[0]) - D_inv_sqrt @ A @ D_inv_sqrt\n",
    "    return L\n",
    "\n",
    "def graph_spectral_phase_randomize(X, eigvecs, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    X_hat = X @ eigvecs  # project into graph spectral domain\n",
    "    T, N = X_hat.shape\n",
    "    X_surr = np.zeros_like(X_hat)\n",
    "\n",
    "    for i in range(N):\n",
    "        fft_coeff = np.fft.fft(X_hat[:, i])\n",
    "        mag = np.abs(fft_coeff)\n",
    "        phase = np.angle(fft_coeff)\n",
    "        num_phases = len(fft_coeff)\n",
    "\n",
    "        # randomize phases symmetrically except DC and Nyquist (if even)\n",
    "        random_phases = np.random.uniform(0, 2*np.pi, num_phases // 2 - 1)\n",
    "        new_phase = np.copy(phase)\n",
    "        new_phase[1:num_phases//2] = random_phases\n",
    "        new_phase[-(num_phases//2)+1:] = -random_phases[::-1]\n",
    "\n",
    "        new_fft = mag * np.exp(1j * new_phase)\n",
    "        X_surr[:, i] = np.fft.ifft(new_fft).real\n",
    "\n",
    "    return X_surr @ eigvecs.T  # back-project into time domain\n",
    "\n",
    "def energy_based_split(eigvals, energy_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Implements energy-based eigenvector split following Preti and Van De Ville.\n",
    "    Splits eigenvectors into low and high frequency sets such that\n",
    "    cumulative energy of low freq <= threshold.\n",
    "    \"\"\"\n",
    "    total_energy = np.sum(eigvals)\n",
    "    cum_energy = np.cumsum(eigvals)\n",
    "    K = np.searchsorted(cum_energy / total_energy, energy_threshold) + 1\n",
    "    return K\n",
    "\n",
    "def compute_SDI_informed(A, X, num_surrogates=100, energy_threshold=0.5, seed=None):\n",
    "    # Normalize functional data (demean + std)\n",
    "    X = X - X.mean(axis=0)\n",
    "    X = X / (X.std(axis=0) + 1e-10)\n",
    "\n",
    "    T, N = X.shape\n",
    "    L = compute_structural_laplacian(A)\n",
    "    eigvals, eigvecs = eigh(L)\n",
    "\n",
    "    # Energy-based eigenvector split\n",
    "    K = energy_based_split(eigvals, energy_threshold=energy_threshold)\n",
    "    # print(f\"Energy split at K={K} (energy threshold={energy_threshold})\")\n",
    "\n",
    "    Vlow, Vhigh = eigvecs[:, :K], eigvecs[:, K:]\n",
    "\n",
    "    N_c_surr, N_d_surr = np.empty((N, num_surrogates)), np.empty((N, num_surrogates))\n",
    "\n",
    "    for s in range(num_surrogates):\n",
    "        X_surr = graph_spectral_phase_randomize(X, eigvecs, seed=seed+s if seed else None)\n",
    "        X_hat = X_surr @ eigvecs\n",
    "\n",
    "        X_c = X_hat[:, :K] @ Vlow.T\n",
    "        X_d = X_hat[:, K:] @ Vhigh.T\n",
    "\n",
    "        for r in range(N):\n",
    "            N_c_surr[r, s] = np.linalg.norm(X_c[:, r])\n",
    "            N_d_surr[r, s] = np.linalg.norm(X_d[:, r])\n",
    "\n",
    "    SDI = N_d_surr / (N_c_surr + 1e-10)\n",
    "    mean_SDI = np.mean(SDI, axis=1)\n",
    "\n",
    "    # Min-max normalize SDI between 0 and 1 per patient\n",
    "    min_val, max_val = np.min(mean_SDI), np.max(mean_SDI)\n",
    "    if max_val - min_val > 0:\n",
    "        mean_SDI_norm = (mean_SDI - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        mean_SDI_norm = np.zeros_like(mean_SDI)\n",
    "\n",
    "    return mean_SDI_norm, K\n",
    "\n",
    "def main(functional_dir, structural_dir, output_csv_path, num_surrogates=100, energy_threshold=0.5, seed=42):\n",
    "    func_files = {os.path.splitext(f)[0]: os.path.join(functional_dir, f)\n",
    "                  for f in os.listdir(functional_dir) if f.endswith('.ts')}\n",
    "    struct_files = {os.path.splitext(f)[0].replace('_5000', ''): os.path.join(structural_dir, f)\n",
    "                    for f in os.listdir(structural_dir) if f.endswith('.sc')}\n",
    "\n",
    "    common_patients = set(func_files.keys()) & set(struct_files.keys())\n",
    "    print(f\"Found {len(common_patients)} patients with matching data.\")\n",
    "\n",
    "    results = []\n",
    "    max_nodes = 0\n",
    "\n",
    "    # For plotting examples\n",
    "    example_plotted = 0\n",
    "    max_examples = 3\n",
    "\n",
    "    for pid in sorted(common_patients):\n",
    "        func_path = func_files[pid]\n",
    "        struct_path = struct_files[pid]\n",
    "\n",
    "        try:\n",
    "            X = np.loadtxt(func_path)\n",
    "            A = np.loadtxt(struct_path)\n",
    "\n",
    "            print(f\"Patient {pid}: Functional shape {X.shape}, Structural shape {A.shape}\")\n",
    "\n",
    "            if X.size == 0 or A.size == 0:\n",
    "                print(f\"Skipping {pid}: empty data\")\n",
    "                continue\n",
    "\n",
    "            if len(A.shape) != 2 or A.shape[0] != A.shape[1]:\n",
    "                print(f\"Skipping {pid}: Structural matrix not square {A.shape}\")\n",
    "                continue\n",
    "\n",
    "            if len(X.shape) != 2:\n",
    "                print(f\"Skipping {pid}: Functional data not 2D {X.shape}\")\n",
    "                continue\n",
    "\n",
    "            T, N_f = X.shape\n",
    "            N_s = A.shape[0]\n",
    "\n",
    "            # Truncate to min dimension to fix mismatch\n",
    "            N = min(N_f, N_s)\n",
    "            if N == 0:\n",
    "                print(f\"Skipping {pid}: zero dimension after truncation\")\n",
    "                continue\n",
    "\n",
    "            # Truncate matrices\n",
    "            X = X[:, :N]\n",
    "            A = A[:N, :N]\n",
    "\n",
    "            # Normalize structural matrix between 0 and 1\n",
    "            A_norm = normalize_matrix(A)\n",
    "\n",
    "            # Plot first few patients\n",
    "            if example_plotted < max_examples:\n",
    "                print(f\"Plotting matrices for patient {pid}\")\n",
    "                plot_matrix(X, f\"Functional data (fMRI) - Patient {pid}\", cmap='coolwarm')\n",
    "                plot_matrix(A_norm, f\"Structural Connectivity (normalized) - Patient {pid}\")\n",
    "                example_plotted += 1\n",
    "\n",
    "            sdi_norm, K = compute_SDI_informed(A_norm, X, num_surrogates=num_surrogates,\n",
    "                                              energy_threshold=energy_threshold, seed=seed)\n",
    "\n",
    "            results.append((pid, sdi_norm))\n",
    "            max_nodes = max(max_nodes, len(sdi_norm))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pid}: {e}\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    with open(output_csv_path, 'w', newline='') as f_out:\n",
    "        writer = csv.writer(f_out)\n",
    "        header = ['PatientID'] + [f'SDI_Node_{i+1}' for i in range(max_nodes)]\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for pid, sdi in results:\n",
    "            row = [pid] + list(sdi) + [np.nan]*(max_nodes - len(sdi))\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"Saved all SDI results to {output_csv_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    functional_dir = \"/Users/arnavkarnik/Documents/Brain-Structure-Function-Coupling-and-Graph-Laplacians-in-Neuroimaging-for-Disease-Characterization/REST2_RL\"\n",
    "    structural_dir = \"/Users/arnavkarnik/Documents/Brain-Structure-Function-Coupling-and-Graph-Laplacians-in-Neuroimaging-for-Disease-Characterization/SC_yeo_100\"\n",
    "    output_csv_path = \"/Users/arnavkarnik/Documents/Brain-Structure-Function-Coupling-and-Graph-Laplacians-in-Neuroimaging-for-Disease-Characterization/SDI_results/all_patients_SDI_informed_normalized.csv\"\n",
    "\n",
    "    main(functional_dir, structural_dir, output_csv_path,\n",
    "         num_surrogates=100,\n",
    "         energy_threshold=0.5,\n",
    "         seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e89160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "def plot_matrix(mat, title, cmap='viridis'):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(mat, cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def normalize_matrix(mat):\n",
    "    min_val = np.min(mat)\n",
    "    max_val = np.max(mat)\n",
    "    if max_val - min_val == 0:\n",
    "        return np.zeros_like(mat)\n",
    "    return (mat - min_val) / (max_val - min_val)\n",
    "\n",
    "def compute_structural_laplacian(A):\n",
    "    D = np.diag(np.sum(A, axis=1))\n",
    "    with np.errstate(divide='ignore'):\n",
    "        D_inv_sqrt = np.diag(1.0 / np.sqrt(np.sum(A, axis=1)))\n",
    "    D_inv_sqrt[np.isinf(D_inv_sqrt)] = 0\n",
    "    L = np.eye(A.shape[0]) - D_inv_sqrt @ A @ D_inv_sqrt\n",
    "    return L\n",
    "\n",
    "def graph_spectral_phase_randomize(X, eigvecs, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    X_hat = X @ eigvecs  # project into graph spectral domain\n",
    "    T, N = X_hat.shape\n",
    "    X_surr = np.zeros_like(X_hat)\n",
    "\n",
    "    for i in range(N):\n",
    "        fft_coeff = np.fft.fft(X_hat[:, i])\n",
    "        mag = np.abs(fft_coeff)\n",
    "        phase = np.angle(fft_coeff)\n",
    "        num_phases = len(fft_coeff)\n",
    "\n",
    "        # randomize phases symmetrically except DC and Nyquist (if even)\n",
    "        random_phases = np.random.uniform(0, 2*np.pi, num_phases // 2 - 1)\n",
    "        new_phase = np.copy(phase)\n",
    "        new_phase[1:num_phases//2] = random_phases\n",
    "        new_phase[-(num_phases//2)+1:] = -random_phases[::-1]\n",
    "\n",
    "        new_fft = mag * np.exp(1j * new_phase)\n",
    "        X_surr[:, i] = np.fft.ifft(new_fft).real\n",
    "\n",
    "    return X_surr @ eigvecs.T  # back-project into time domain\n",
    "\n",
    "def energy_based_split(eigvals, energy_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Implements energy-based eigenvector split following Preti and Van De Ville.\n",
    "    Splits eigenvectors into low and high frequency sets such that\n",
    "    cumulative energy of low freq <= threshold.\n",
    "    \"\"\"\n",
    "    total_energy = np.sum(eigvals)\n",
    "    cum_energy = np.cumsum(eigvals)\n",
    "    K = np.searchsorted(cum_energy / total_energy, energy_threshold) + 1\n",
    "    return K\n",
    "\n",
    "def compute_SDI_informed(A, X, num_surrogates=100, energy_threshold=0.5, seed=None):\n",
    "    # Normalize functional data (demean + std)\n",
    "    X = X - X.mean(axis=0)\n",
    "    X = X / (X.std(axis=0) + 1e-10)\n",
    "\n",
    "    T, N = X.shape\n",
    "    L = compute_structural_laplacian(A)\n",
    "    eigvals, eigvecs = eigh(L)\n",
    "\n",
    "    # Energy-based eigenvector split\n",
    "    K = energy_based_split(eigvals, energy_threshold=energy_threshold)\n",
    "    # print(f\"Energy split at K={K} (energy threshold={energy_threshold})\")\n",
    "\n",
    "    Vlow, Vhigh = eigvecs[:, :K], eigvecs[:, K:]\n",
    "\n",
    "    N_c_surr, N_d_surr = np.empty((N, num_surrogates)), np.empty((N, num_surrogates))\n",
    "\n",
    "    for s in range(num_surrogates):\n",
    "        X_surr = graph_spectral_phase_randomize(X, eigvecs, seed=seed+s if seed else None)\n",
    "        X_hat = X_surr @ eigvecs\n",
    "\n",
    "        X_c = X_hat[:, :K] @ Vlow.T\n",
    "        X_d = X_hat[:, K:] @ Vhigh.T\n",
    "\n",
    "        for r in range(N):\n",
    "            N_c_surr[r, s] = np.linalg.norm(X_c[:, r])\n",
    "            N_d_surr[r, s] = np.linalg.norm(X_d[:, r])\n",
    "\n",
    "    SDI = N_d_surr / (N_c_surr + 1e-10)\n",
    "    mean_SDI = np.mean(SDI, axis=1)\n",
    "\n",
    "    # Min-max normalize SDI between 0 and 1 per patient\n",
    "    min_val, max_val = np.min(mean_SDI), np.max(mean_SDI)\n",
    "    if max_val - min_val > 0:\n",
    "        mean_SDI_norm = (mean_SDI - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        mean_SDI_norm = np.zeros_like(mean_SDI)\n",
    "\n",
    "    return mean_SDI_norm, K\n",
    "\n",
    "def main(functional_dir, structural_dir, output_csv_path, num_surrogates=100, energy_threshold=0.5, seed=42):\n",
    "    func_files = {os.path.splitext(f)[0]: os.path.join(functional_dir, f)\n",
    "                  for f in os.listdir(functional_dir) if f.endswith('.ts')}\n",
    "    struct_files = {os.path.splitext(f)[0].replace('_5000', ''): os.path.join(structural_dir, f)\n",
    "                    for f in os.listdir(structural_dir) if f.endswith('.sc')}\n",
    "\n",
    "    common_patients = set(func_files.keys()) & set(struct_files.keys())\n",
    "    print(f\"Found {len(common_patients)} patients with matching data.\")\n",
    "\n",
    "    results = []\n",
    "    max_nodes = 0\n",
    "\n",
    "    # For plotting examples\n",
    "    example_plotted = 0\n",
    "    max_examples = 3\n",
    "\n",
    "    for pid in sorted(common_patients):\n",
    "        func_path = func_files[pid]\n",
    "        struct_path = struct_files[pid]\n",
    "\n",
    "        try:\n",
    "            X = np.loadtxt(func_path)\n",
    "            A = np.loadtxt(struct_path)\n",
    "\n",
    "            print(f\"Patient {pid}: Functional shape {X.shape}, Structural shape {A.shape}\")\n",
    "\n",
    "            if X.size == 0 or A.size == 0:\n",
    "                print(f\"Skipping {pid}: empty data\")\n",
    "                continue\n",
    "\n",
    "            if len(A.shape) != 2 or A.shape[0] != A.shape[1]:\n",
    "                print(f\"Skipping {pid}: Structural matrix not square {A.shape}\")\n",
    "                continue\n",
    "\n",
    "            if len(X.shape) != 2:\n",
    "                print(f\"Skipping {pid}: Functional data not 2D {X.shape}\")\n",
    "                continue\n",
    "\n",
    "            T, N_f = X.shape\n",
    "            N_s = A.shape[0]\n",
    "\n",
    "            # Truncate to max 68 nodes or smaller dimension to fix mismatch\n",
    "            N = min(68, N_f, N_s)\n",
    "            if N == 0:\n",
    "                print(f\"Skipping {pid}: zero dimension after truncation\")\n",
    "                continue\n",
    "\n",
    "            # Truncate matrices\n",
    "            X = X[:, :N]\n",
    "            A = A[:N, :N]\n",
    "\n",
    "            # Normalize structural matrix between 0 and 1\n",
    "            A_norm = normalize_matrix(A)\n",
    "\n",
    "            # Plot first few patients\n",
    "            if example_plotted < max_examples:\n",
    "                print(f\"Plotting matrices for patient {pid}\")\n",
    "                plot_matrix(X, f\"Functional data (fMRI) - Patient {pid}\", cmap='coolwarm')\n",
    "                plot_matrix(A_norm, f\"Structural Connectivity (normalized) - Patient {pid}\")\n",
    "                example_plotted += 1\n",
    "\n",
    "            sdi_norm, K = compute_SDI_informed(A_norm, X, num_surrogates=num_surrogates,\n",
    "                                              energy_threshold=energy_threshold, seed=seed)\n",
    "\n",
    "            results.append((pid, sdi_norm))\n",
    "            max_nodes = max(max_nodes, len(sdi_norm))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pid}: {e}\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    with open(output_csv_path, 'w', newline='') as f_out:\n",
    "        writer = csv.writer(f_out)\n",
    "        header = ['PatientID'] + [f'SDI_Node_{i+1}' for i in range(max_nodes)]\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for pid, sdi in results:\n",
    "            row = [pid] + list(sdi) + [np.nan]*(max_nodes - len(sdi))\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"Saved all SDI results to {output_csv_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    functional_dir = \"/Users/arnavkarnik/Documents/Classification/REST2_RL\"\n",
    "    structural_dir = \"/Users/arnavkarnik/Documents/Classification/SC_yeo_100\"\n",
    "    output_csv_path = \"/Users/arnavkarnik/Documents/Classification/results/all_patients_SDI_informed_normalized_hcp.csv\"\n",
    "\n",
    "    main(functional_dir, structural_dir, output_csv_path,\n",
    "         num_surrogates=100,\n",
    "         energy_threshold=0.5,\n",
    "         seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5378ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "\n",
    "# Path to your SDI results CSV\n",
    "csv_path = \"/Users/arnavkarnik/Documents/Classification/results/all_patients_SDI_informed_normalized_hcp.csv\"\n",
    "\n",
    "# Load SDI data from CSV (skip header)\n",
    "patient_ids = []\n",
    "sdi_data = []\n",
    "\n",
    "with open(csv_path, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)  # Skip header\n",
    "    for row in reader:\n",
    "        patient_ids.append(row[0])\n",
    "        sdi_vals = [float(x) if x != '' else np.nan for x in row[1:]]\n",
    "        sdi_data.append(sdi_vals)\n",
    "\n",
    "sdi_array = np.array(sdi_data)  # shape: (num_patients, num_nodes)\n",
    "\n",
    "# Replace empty/nan with np.nan explicitly\n",
    "sdi_array = np.where(np.isnan(sdi_array), np.nan, sdi_array)\n",
    "\n",
    "# Plot 1: Histogram of all SDI values across all nodes and patients\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(sdi_array[~np.isnan(sdi_array)].flatten(), bins=90, color='c', alpha=0.7)\n",
    "plt.title(\"Histogram of all SDI values across all nodes and patients\")\n",
    "plt.xlabel(\"SDI value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Mean ± Std Dev of SDI per brain node across patients\n",
    "mean_sdi = np.nanmean(sdi_array, axis=0)\n",
    "std_sdi = np.nanstd(sdi_array, axis=0)\n",
    "nodes = np.arange(1, len(mean_sdi)+1)\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.errorbar(nodes, mean_sdi, yerr=std_sdi, fmt='-o', ecolor='r', capsize=5)\n",
    "plt.title(\"Mean ± Std Dev of SDI per brain node across patients\")\n",
    "plt.xlabel(\"Brain node\")\n",
    "plt.ylabel(\"SDI\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Distribution of total SDI per patient\n",
    "total_sdi_per_patient = np.nansum(sdi_array, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(total_sdi_per_patient, bins=30, color='m', alpha=0.7)\n",
    "plt.title(\"Distribution of total SDI scores across patients\")\n",
    "plt.xlabel(\"Total SDI\")\n",
    "plt.ylabel(\"Number of patients\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 4: Heatmap of SDI for first 5 patients (or less if fewer patients)\n",
    "num_patients_to_show = min(25, sdi_array.shape[0])\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.heatmap(sdi_array[:num_patients_to_show], cmap='viridis', xticklabels=np.arange(1, sdi_array.shape[1]+1), yticklabels=patient_ids[:num_patients_to_show])\n",
    "plt.title(\"SDI heatmap for first 5 patients (nodes on x-axis)\")\n",
    "plt.xlabel(\"Brain node\")\n",
    "plt.ylabel(\"Patient ID\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410cbe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from nilearn import plotting, datasets\n",
    "\n",
    "# Load Desikan-Killiany atlas (volume)\n",
    "atlas_path = '/Users/arnavkarnik/Documents/Classification/desikanKillianyMNI.nii.gz'\n",
    "atlas_img = nib.load(atlas_path)\n",
    "atlas_data = atlas_img.get_fdata()\n",
    "\n",
    "# Load MNI152 background template\n",
    "mni_template = datasets.load_mni152_template()\n",
    "\n",
    "# Replace this with your actual SDI values (68 regions: 34 left + 34 right)\n",
    "sdi_norm = np.random.rand(68)\n",
    "\n",
    "# Create an empty volume with same shape as atlas\n",
    "sdi_volume = np.zeros_like(atlas_data)\n",
    "\n",
    "# Assign SDI values to voxels based on atlas labels (assumes labels 1–68 map to your SDI)\n",
    "for label in range(1, 69):\n",
    "    sdi_volume[atlas_data == label] = sdi_norm[label - 1]\n",
    "\n",
    "# Create NIfTI image with mapped SDI values and same affine as atlas\n",
    "sdi_img = nib.Nifti1Image(sdi_volume, affine=atlas_img.affine)\n",
    "\n",
    "# Plot on MNI152 template\n",
    "plotting.plot_stat_map(sdi_img, bg_img=mni_template,\n",
    "                       title='SDI values on Desikan-Killiany atlas (MNI space)',\n",
    "                       cmap='coolwarm', threshold=1e-5, colorbar=True)\n",
    "\n",
    "plotting.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45db767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting, datasets\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Load SDI from CSV\n",
    "# -----------------------------\n",
    "csv_path = \"/Users/arnavkarnik/Documents/Classification/results/all_patients_SDI_informed_normalized.csv\"  # ⬅️ Replace with actual path\n",
    "patient_id = \"111312\"                    # ⬅️ Replace with desired patient ID\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df[\"PatientID\"] = df[\"PatientID\"].astype(str)\n",
    "row_match = df[df[\"PatientID\"] == patient_id]\n",
    "\n",
    "if row_match.empty:\n",
    "    raise ValueError(f\"Patient ID {patient_id} not found in CSV.\")\n",
    "\n",
    "sdi_row = row_match.iloc[0]\n",
    "sdi_values = sdi_row.iloc[1:69].to_numpy(dtype=float)  # 68 cortical regions\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Load DK atlas volume\n",
    "# -----------------------------\n",
    "atlas_path = \"/Users/arnavkarnik/Documents/Classification/desikanKillianyMNI.nii.gz\"\n",
    "atlas_img = nib.load(atlas_path)\n",
    "atlas_data = atlas_img.get_fdata()\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Build SDI volume\n",
    "# -----------------------------\n",
    "sdi_volume = np.zeros_like(atlas_data)\n",
    "\n",
    "# DK atlas labels start from 1 to 68 (assuming no subcortical in use)\n",
    "for i in range(68):\n",
    "    region_label = i + 1  # 1-based index\n",
    "    sdi_volume[atlas_data == region_label] = sdi_values[i]\n",
    "\n",
    "sdi_img = nib.Nifti1Image(sdi_volume, affine=atlas_img.affine)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Plot on MNI template\n",
    "# -----------------------------\n",
    "template = datasets.load_mni152_template()\n",
    "\n",
    "display = plotting.plot_stat_map(\n",
    "    sdi_img,\n",
    "    bg_img=template,\n",
    "    title=f\"SDI Map - Patient {patient_id}\",\n",
    "    display_mode=\"ortho\",\n",
    "    threshold=np.percentile(sdi_values, 20),  # show top 80%\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "plotting.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4a76f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "# Desikan-Killiany atlas region names (68 regions)\n",
    "region_names = {\n",
    "    1: \"Caudal middle frontal (LH)\", 2: \"Caudal middle frontal (RH)\",\n",
    "    3: \"Frontal pole (LH)\", 4: \"Frontal pole (RH)\",\n",
    "    5: \"Lateral orbitofrontal (LH)\", 6: \"Lateral orbitofrontal (RH)\",\n",
    "    7: \"Medial orbitofrontal (LH)\", 8: \"Medial orbitofrontal (RH)\",\n",
    "    9: \"Pars opercularis (LH)\", 10: \"Pars opercularis (RH)\",\n",
    "    11: \"Pars orbitalis (LH)\", 12: \"Pars orbitalis (RH)\",\n",
    "    13: \"Pars triangularis (LH)\", 14: \"Pars triangularis (RH)\",\n",
    "    15: \"Rostral middle frontal (LH)\", 16: \"Rostral middle frontal (RH)\",\n",
    "    17: \"Superior frontal (LH)\", 18: \"Superior frontal (RH)\",\n",
    "    19: \"Precentral gyrus (LH)\", 20: \"Precentral gyrus (RH)\",\n",
    "    21: \"Caudal anterior cingulate (LH)\", 22: \"Caudal anterior cingulate (RH)\",\n",
    "    23: \"Rostral anterior cingulate (LH)\", 24: \"Rostral anterior cingulate (RH)\",\n",
    "    25: \"Isthmus cingulate (LH)\", 26: \"Isthmus cingulate (RH)\",\n",
    "    27: \"Insula (LH)\", 28: \"Insula (RH)\",\n",
    "    29: \"Parahippocampal (LH)\", 30: \"Parahippocampal (RH)\",\n",
    "    31: \"Posterior cingulate (LH)\", 32: \"Posterior cingulate (RH)\",\n",
    "    33: \"Bankssts (LH)\", 34: \"Bankssts (RH)\",\n",
    "    35: \"Entorhinal (LH)\", 36: \"Entorhinal (RH)\",\n",
    "    37: \"Inferior temporal (LH)\", 38: \"Inferior temporal (RH)\",\n",
    "    39: \"Middle temporal (LH)\", 40: \"Middle temporal (RH)\",\n",
    "    41: \"Superior temporal (LH)\", 42: \"Superior temporal (RH)\",\n",
    "    43: \"Temporal pole (LH)\", 44: \"Temporal pole (RH)\",\n",
    "    45: \"Transverse temporal (LH)\", 46: \"Transverse temporal (RH)\",\n",
    "    47: \"Inferior parietal (LH)\", 48: \"Inferior parietal (RH)\",\n",
    "    49: \"Paracentral (LH)\", 50: \"Paracentral (RH)\",\n",
    "    51: \"Postcentral (LH)\", 52: \"Postcentral (RH)\",\n",
    "    53: \"Precuneus (LH)\", 54: \"Precuneus (RH)\",\n",
    "    55: \"Superior parietal (LH)\", 56: \"Superior parietal (RH)\",\n",
    "    57: \"Supramarginal (LH)\", 58: \"Supramarginal (RH)\",\n",
    "    59: \"Pericalcarine (LH)\", 60: \"Pericalcarine (RH)\",\n",
    "    61: \"Fusiform (LH)\", 62: \"Fusiform (RH)\",\n",
    "    63: \"Cuneus (LH)\", 64: \"Cuneus (RH)\",\n",
    "    65: \"Lateral occipital (LH)\", 66: \"Lateral occipital (RH)\",\n",
    "    67: \"Lingual (LH)\", 68: \"Lingual (RH)\"\n",
    "}\n",
    "\n",
    "\n",
    "# -------- Step 1: Load SDI values from CSV --------\n",
    "csv_path = \"SDI_results/all_patients_SDI_informed_normalized.csv\"\n",
    "patient_id = \"100307\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df[\"PatientID\"] = df[\"PatientID\"].astype(str)\n",
    "row = df[df[\"PatientID\"] == patient_id]\n",
    "\n",
    "if row.empty:\n",
    "    raise ValueError(f\"Patient {patient_id} not found in CSV\")\n",
    "\n",
    "# Extract exactly 68 SDI values (first 68 columns after PatientID)\n",
    "sdi_values = row.iloc[0, 1:69].to_numpy(dtype=float)\n",
    "\n",
    "# -------- Step 2: Load the Desikan-Killiany atlas --------\n",
    "atlas_path = \"/Users/arnavkarnik/Documents/Classification/desikanKillianyMNI.nii.gz\"\n",
    "atlas_img = nib.load(atlas_path)\n",
    "atlas_data = atlas_img.get_fdata().astype(int)\n",
    "\n",
    "# -------- Step 3: Identify top N coupled/decoupled regions --------\n",
    "N = 10\n",
    "top_indices = np.argsort(sdi_values)[-N:][::-1]\n",
    "bottom_indices = np.argsort(sdi_values)[:N]\n",
    "\n",
    "# -------- Step 4: Print with region names --------\n",
    "print(\"Top Coupled Regions (High SDI):\")\n",
    "for i in top_indices:\n",
    "    region_id = i + 1\n",
    "    region_name = region_names.get(region_id, f\"Unknown region {region_id}\")\n",
    "    print(f\"Region {region_id} ({region_name}) — SDI: {sdi_values[i]:.4f}\")\n",
    "\n",
    "print(\"\\nTop Decoupled Regions (Low SDI):\")\n",
    "for i in bottom_indices:\n",
    "    region_id = i + 1\n",
    "    region_name = region_names.get(region_id, f\"Unknown region {region_id}\")\n",
    "    print(f\"Region {region_id} ({region_name}) — SDI: {sdi_values[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10603db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dictionary: Desikan-Killiany atlas region ID -> region name\n",
    "region_names = {\n",
    "    1: \"Caudal middle frontal (LH)\", 2: \"Caudal middle frontal (RH)\",\n",
    "    3: \"Frontal pole (LH)\", 4: \"Frontal pole (RH)\",\n",
    "    5: \"Lateral orbitofrontal (LH)\", 6: \"Lateral orbitofrontal (RH)\",\n",
    "    7: \"Medial orbitofrontal (LH)\", 8: \"Medial orbitofrontal (RH)\",\n",
    "    9: \"Pars opercularis (LH)\", 10: \"Pars opercularis (RH)\",\n",
    "    11: \"Pars orbitalis (LH)\", 12: \"Pars orbitalis (RH)\",\n",
    "    13: \"Pars triangularis (LH)\", 14: \"Pars triangularis (RH)\",\n",
    "    15: \"Rostral middle frontal (LH)\", 16: \"Rostral middle frontal (RH)\",\n",
    "    17: \"Superior frontal (LH)\", 18: \"Superior frontal (RH)\",\n",
    "    19: \"Precentral gyrus (LH)\", 20: \"Precentral gyrus (RH)\",\n",
    "    21: \"Caudal anterior cingulate (LH)\", 22: \"Caudal anterior cingulate (RH)\",\n",
    "    23: \"Rostral anterior cingulate (LH)\", 24: \"Rostral anterior cingulate (RH)\",\n",
    "    25: \"Isthmus cingulate (LH)\", 26: \"Isthmus cingulate (RH)\",\n",
    "    27: \"Insula (LH)\", 28: \"Insula (RH)\",\n",
    "    29: \"Parahippocampal (LH)\", 30: \"Parahippocampal (RH)\",\n",
    "    31: \"Posterior cingulate (LH)\", 32: \"Posterior cingulate (RH)\",\n",
    "    33: \"Bankssts (LH)\", 34: \"Bankssts (RH)\",\n",
    "    35: \"Entorhinal (LH)\", 36: \"Entorhinal (RH)\",\n",
    "    37: \"Inferior temporal (LH)\", 38: \"Inferior temporal (RH)\",\n",
    "    39: \"Middle temporal (LH)\", 40: \"Middle temporal (RH)\",\n",
    "    41: \"Superior temporal (LH)\", 42: \"Superior temporal (RH)\",\n",
    "    43: \"Temporal pole (LH)\", 44: \"Temporal pole (RH)\",\n",
    "    45: \"Transverse temporal (LH)\", 46: \"Transverse temporal (RH)\",\n",
    "    47: \"Inferior parietal (LH)\", 48: \"Inferior parietal (RH)\",\n",
    "    49: \"Paracentral (LH)\", 50: \"Paracentral (RH)\",\n",
    "    51: \"Postcentral (LH)\", 52: \"Postcentral (RH)\",\n",
    "    53: \"Precuneus (LH)\", 54: \"Precuneus (RH)\",\n",
    "    55: \"Superior parietal (LH)\", 56: \"Superior parietal (RH)\",\n",
    "    57: \"Supramarginal (LH)\", 58: \"Supramarginal (RH)\",\n",
    "    59: \"Pericalcarine (LH)\", 60: \"Pericalcarine (RH)\",\n",
    "    61: \"Fusiform (LH)\", 62: \"Fusiform (RH)\",\n",
    "    63: \"Cuneus (LH)\", 64: \"Cuneus (RH)\",\n",
    "    65: \"Lateral occipital (LH)\", 66: \"Lateral occipital (RH)\",\n",
    "    67: \"Lingual (LH)\", 68: \"Lingual (RH)\"\n",
    "}\n",
    "\n",
    "\n",
    "# -------- Step 1: Load SDI values from CSV --------\n",
    "csv_path = \"SDI_results/all_patients_SDI_informed_normalized.csv\"\n",
    "patient_id = \"100307\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df[\"PatientID\"] = df[\"PatientID\"].astype(str)\n",
    "row = df[df[\"PatientID\"] == patient_id]\n",
    "\n",
    "if row.empty:\n",
    "    raise ValueError(f\"Patient {patient_id} not found in CSV\")\n",
    "\n",
    "sdi_values = row.iloc[0, 1:401].to_numpy(dtype=float)  # 400 regions\n",
    "\n",
    "# -------- Step 2: Load the Desikan-Killiany atlas --------\n",
    "atlas_path = \"/Users/arnavkarnik/Documents/Classification/desikanKillianyMNI.nii.gz\"\n",
    "atlas_img = nib.load(atlas_path)\n",
    "atlas_data = atlas_img.get_fdata().astype(int)\n",
    "\n",
    "# -------- Step 3: Identify top N coupled/decoupled regions --------\n",
    "N = 10\n",
    "top_indices = np.argsort(sdi_values)[-N:][::-1]\n",
    "bottom_indices = np.argsort(sdi_values)[:N]\n",
    "\n",
    "# -------- Step 4: Print with region names --------\n",
    "print(\"Top Coupled Regions (High SDI):\")\n",
    "for i in top_indices:\n",
    "    region_id = i + 1\n",
    "    region_name = region_names.get(region_id, f\"Unknown region {region_id}\")\n",
    "    print(f\"Region {region_id} ({region_name}) — SDI: {sdi_values[i]:.4f}\")\n",
    "\n",
    "print(\"\\nTop Decoupled Regions (Low SDI):\")\n",
    "for i in bottom_indices:\n",
    "    region_id = i + 1\n",
    "    region_name = region_names.get(region_id, f\"Unknown region {region_id}\")\n",
    "    print(f\"Region {region_id} ({region_name}) — SDI: {sdi_values[i]:.4f}\")\n",
    "\n",
    "# -------- Step 5: Create masks for visualization --------\n",
    "top_mask = np.isin(atlas_data, [i + 1 for i in top_indices])\n",
    "bottom_mask = np.isin(atlas_data, [i + 1 for i in bottom_indices])\n",
    "\n",
    "# Create combined mask:\n",
    "# 0 = background, 1 = top coupled (red), 2 = top decoupled (blue)\n",
    "combined_mask = np.zeros(atlas_data.shape, dtype=np.uint8)\n",
    "combined_mask[top_mask] = 1\n",
    "combined_mask[bottom_mask] = 2\n",
    "\n",
    "combined_img = nib.Nifti1Image(combined_mask, affine=atlas_img.affine)\n",
    "\n",
    "# -------- Step 6: Plot --------\n",
    "cmap = plt.cm.get_cmap('coolwarm', 3)  # 3 discrete colors: 0-bg, 1-red, 2-blue\n",
    "\n",
    "display = plotting.plot_roi(combined_img,\n",
    "                            title=\"Top Coupled (red) & Decoupled (blue) Regions\",\n",
    "                            cmap=cmap,\n",
    "                            alpha=0.7)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
